# 流式推理工作流程

<cite>
**本文档引用的文件**   
- [token2wav_dit.py](file://runtime/triton_trtllm/token2wav_dit.py)
- [flow.py](file://cosyvoice/flow/flow.py)
- [decoder.py](file://cosyvoice/flow/decoder.py)
- [flow_matching.py](file://cosyvoice/flow/flow_matching.py)
- [generator.py](file://cosyvoice/hifigan/generator.py)
- [mask.py](file://cosyvoice/utils/mask.py)
</cite>

## 目录
1. [系统初始化与缓存管理](#系统初始化与缓存管理)
2. [流式推理执行逻辑](#流式推理执行逻辑)
3. [数据流与状态转换时序图](#数据流与状态转换时序图)
4. [音频块平滑连接机制](#音频块平滑连接机制)

## 系统初始化与缓存管理

`CosyVoice2_Token2Wav` 类在初始化时，会加载流匹配模型（flow model）和声码器（HiFi-GAN）的权重，并根据配置决定是否使用 TensorRT 进行加速。系统为每个说话人（speaker）和请求（request）建立独立的缓存机制，以维持跨块推理的隐藏状态一致性。

在 `__init__` 方法中，系统初始化了多个缓存字典：
- `self.streaming_flow_cache`：用于存储流匹配模型的推理缓存
- `self.speaker_cache`：用于存储说话人相关的音频特征和模型缓存
- `self.hift_cache_dict`：用于存储声码器的中间状态缓存

当为新说话人建立缓存时，系统会调用 `get_prompt_audio_cache_for_streaming_tts` 方法，该方法通过 `flow.setup_cache` 为流匹配模型预计算并存储初始缓存状态，包括 `estimator_att_cache` 和 `estimator_cnn_cache` 等关键组件。

**Section sources**
- [token2wav_dit.py](file://runtime/triton_trtllm/token2wav_dit.py#L115-L174)

## 流式推理执行逻辑

`forward_streaming` 方法是流式推理的核心，它实现了从语音标记流到音频输出的端到端处理。该方法的执行逻辑如下：

1. **说话人缓存管理**：如果 `speaker_id` 不在 `speaker_cache` 中，系统会使用提供的 `prompt_audio` 计算并存储该说话人的嵌入向量（spk_emb）和流模型缓存。
2. **请求缓存初始化**：如果 `request_id` 不在 `streaming_flow_cache` 中，系统会从 `speaker_cache` 复制初始缓存状态，并为声码器初始化空缓存。
3. **分块推理**：系统将输入的语音标记流分块，调用 `flow.inference_chunk` 方法进行流匹配模型的推理。该方法利用 `estimator_att_cache` 和 `estimator_cnn_cache` 维持跨块的隐藏状态一致性。
4. **缓存更新与管理**：每次推理后，系统会更新 `streaming_flow_cache`。为防止缓存无限增长，系统会定期截断 `estimator_att_cache`，保留与提示音频长度相当的部分和最近的100帧。

```mermaid
sequenceDiagram
participant Client as 客户端
participant Token2Wav as CosyVoice2_Token2Wav
participant Flow as 流匹配模型
participant HiFiGAN as 声码器
Client->>Token2Wav : 发送语音标记块
Token2Wav->>Token2Wav : 检查说话人缓存
alt 新说话人
Token2Wav->>Token2Wav : 计算spk_emb并建立缓存
end
Token2Wav->>Token2Wav : 检查请求缓存
alt 新请求
Token2Wav->>Token2Wav : 初始化流模型和声码器缓存
end
Token2Wav->>Flow : 调用inference_chunk(输入, 缓存)
Flow->>Flow : 使用att_cache和cnn_cache维持状态
Flow-->>Token2Wav : 返回音频块和更新后的缓存
Token2Wav->>Token2Wav : 更新streaming_flow_cache
Token2Wav->>HiFiGAN : 使用更新的缓存解码
HiFiGAN-->>Token2Wav : 返回音频
Token2Wav->>Client : 返回音频块
```

**Diagram sources**
- [token2wav_dit.py](file://runtime/triton_trtllm/token2wav_dit.py#L390-L462)
- [flow.py](file://cosyvoice/flow/flow.py)

## 数据流与状态转换时序图

下图展示了数据在各个组件间的流动过程以及关键状态的转换。

```mermaid
stateDiagram-v2
[*] --> 初始化
state 初始化 {
[*] --> 加载模型
加载模型 --> 建立缓存
建立缓存 --> 等待输入
}
等待输入 --> 接收标记块 : 接收到语音标记流
接收标记块 --> 检查缓存 : 验证speaker_id和request_id
检查缓存 --> 新说话人 : speaker_id不存在
检查缓存 --> 新请求 : request_id不存在
新说话人 --> 计算spk_emb : 使用prompt_audio
新说话人 --> 建立流缓存 : flow.setup_cache()
新请求 --> 初始化流缓存 : 从speaker_cache复制
新请求 --> 初始化声码器缓存 : 创建空缓存
检查缓存 --> 分块推理 : 缓存已存在
新说话人 --> 分块推理
新请求 --> 分块推理
分块推理 --> 调用inference_chunk : flow.inference_chunk(token, cache)
调用inference_chunk --> 更新流缓存 : streaming_flow_cache = new_cache
更新流缓存 --> 截断缓存 : 限制estimator_att_cache大小
截断缓存 --> 声码器解码 : hift(mel, hift_cache_source)
声码器解码 --> 应用淡入淡出 : fade_in_out(speech, hift_cache_speech)
应用淡入淡出 --> 更新声码器缓存 : hift_cache_dict[request_id]
更新声码器缓存 --> 发送音频块 : 返回给客户端
发送音频块 --> 等待输入 : 准备接收下一块
发送音频块 --> 结束 : last_chunk=True
结束 --> 清理缓存 : 移除request_id的缓存
清理缓存 --> [*]
```

**Diagram sources**
- [token2wav_dit.py](file://runtime/triton_trtllm/token2wav_dit.py)
- [decoder.py](file://cosyvoice/flow/decoder.py)
- [flow_matching.py](file://cosyvoice/flow/flow_matching.py)

## 音频块平滑连接机制

为了消除流式解码中音频块之间的连接处可能出现的突变或不连续，系统采用了淡入淡出（fade-in-out）技术。该机制通过一个汉明窗（Hamming window）对相邻音频块的重叠部分进行加权混合。

具体实现如下：
1. 系统在初始化时创建一个长度为 `2 * source_cache_len` 的汉明窗。
2. 在每次生成新的音频块后，系统检查是否存在先前的音频缓存。
3. 如果存在，则使用 `fade_in_out` 函数将新生成的音频块与缓存中的上一块音频进行平滑过渡。
4. 过渡完成后，系统更新声码器缓存，保留最新的音频片段用于下一次过渡。

```mermaid
flowchart TD
A[开始] --> B[生成新音频块]
B --> C{存在缓存音频?}
C --> |是| D[应用淡入淡出]
C --> |否| E[直接输出]
D --> F[使用汉明窗混合重叠部分]
F --> G[更新声码器缓存]
G --> H[输出音频块]
E --> H
H --> I{最后一块?}
I --> |否| B
I --> |是| J[清理缓存]
J --> K[结束]
```

**Diagram sources**
- [token2wav_dit.py](file://runtime/triton_trtllm/token2wav_dit.py#L38-L46)
- [generator.py](file://cosyvoice/hifigan/generator.py)
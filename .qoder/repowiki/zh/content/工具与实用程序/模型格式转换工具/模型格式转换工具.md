# 模型格式转换工具

<cite>
**本文档引用的文件**   
- [huggingface_to_pretrained.py](file://examples/grpo/cosyvoice2/huggingface_to_pretrained.py)
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py)
- [cosyvoice2.yaml](file://examples/libritts/cosyvoice2/conf/cosyvoice2.yaml)
- [cosyvoice.py](file://cosyvoice/cli/cosyvoice.py)
- [model.py](file://cosyvoice/cli/model.py)
- [llm.py](file://cosyvoice/llm/llm.py)
</cite>

## 目录
1. [引言](#引言)
2. [工具概述](#工具概述)
3. [目录结构映射](#目录结构映射)
4. [权重重命名规则](#权重重命名规则)
5. [配置文件适配方法](#配置文件适配方法)
6. [版本兼容性注意事项](#版本兼容性注意事项)
7. [转换流程示例](#转换流程示例)
8. [常见错误与解决方案](#常见错误与解决方案)
9. [结论](#结论)

## 引言
在语音合成模型的开发与部署过程中，模型格式的互操作性至关重要。CosyVoice系列模型通过提供`huggingface_to_pretrained.py`和`pretrained_to_huggingface.py`两个核心工具，实现了与Hugging Face生态系统的无缝集成。这两个工具不仅促进了模型的共享与发布，还为研究人员和开发者提供了灵活的模型转换能力。本文档将深入探讨这两个工具的关键作用、转换机制以及实际应用中的注意事项。

## 工具概述
`huggingface_to_pretrained.py`和`pretrained_to_huggingface.py`是CosyVoice项目中用于实现模型格式双向转换的核心脚本。前者负责将Hugging Face格式的检查点转换为CosyVoice内部使用的预训练模型格式（`.pt`文件），后者则实现反向转换，支持模型在Hugging Face平台上的共享与发布。

**huggingface_to_pretrained.py**的主要功能是将经过强化学习（RL）训练的CosyVoice2模型从Hugging Face格式转换为CosyVoice内部使用的`llm.pt`格式。该脚本通过读取Hugging Face格式的`safetensors`文件，提取并重命名相关权重，最终保存为PyTorch格式的`llm.pt`文件。此过程涉及对LLM（大语言模型）组件的权重进行重映射，并处理特殊的嵌入层和解码器权重。

**pretrained_to_huggingface.py**则负责将CosyVoice的预训练模型转换为标准的Hugging Face格式。该脚本加载CosyVoice模型，调整其架构以符合Hugging Face Transformers库的要求，包括扩展词汇表、调整嵌入层和解码器，并生成兼容的配置文件和分词器。转换后的模型可以直接在Hugging Face平台上托管和使用，极大地简化了模型的共享和部署流程。

这两个工具共同构成了CosyVoice模型生态互操作性的基础，使得模型能够在不同的框架和平台之间自由流动，促进了技术的开放共享和协作创新。

**Section sources**
- [huggingface_to_pretrained.py](file://examples/grpo/cosyvoice2/huggingface_to_pretrained.py#L1-L72)
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L1-L134)

## 目录结构映射
模型格式转换涉及不同目录结构之间的映射。CosyVoice的预训练模型目录与Hugging Face模型仓库的结构存在显著差异，转换工具需要处理这些差异以确保模型的正确加载和使用。

CosyVoice预训练模型的标准目录结构如下：
```
CosyVoice2-0.5B/
├── llm.pt
├── flow.pt
├── hift.pt
├── spk2info.pt
├── campplus.onnx
├── speech_tokenizer_v2.onnx
└── CosyVoice-BlankEN/
    ├── config.json
    ├── pytorch_model.bin
    └── tokenizer.json
```

而转换后的Hugging Face模型目录结构则遵循Transformers库的标准：
```
transformers_cosyvoice2_llm/
├── config.json
├── pytorch_model.bin
├── tokenizer_config.json
├── special_tokens_map.json
└── generation_config.json
```

`huggingface_to_pretrained.py`主要关注从Hugging Face格式的`pytorch_model.bin`或`safetensors`文件中提取权重，并将其整合到CosyVoice的`llm.pt`文件中。而`pretrained_to_huggingface.py`则需要将CosyVoice模型的多个组件（如`llm.pt`、`flow.pt`）中的相关权重提取出来，合并到一个单一的`pytorch_model.bin`文件中，并生成所有必要的Hugging Face配置文件。

这种目录结构的映射是双向转换的基础，确保了模型在不同环境下的可移植性和兼容性。

**Section sources**
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L54-L58)
- [cosyvoice.py](file://cosyvoice/cli/cosyvoice.py#L277-L285)

## 权重重命名规则
权重的重命名是模型格式转换的核心环节，它确保了不同框架下模型参数的正确对应。`huggingface_to_pretrained.py`和`pretrained_to_huggingface.py`都实现了复杂的权重映射逻辑。

在`huggingface_to_pretrained.py`中，权重重命名规则如下：
- 所有以`lm_head.bias`开头的权重被忽略，因为强化学习训练的模型禁用了`lm_head`的偏置。
- 其他所有权重的键名前都会加上`llm.model.`前缀，例如`model.embed_tokens.weight`变为`llm.model.model.embed_tokens.weight`。
- 特殊处理`lm_head`和`model.embed_tokens`的权重：从原始权重中切片出与语音token相关的部分，并分别赋值给`llm_decoder.weight`和`speech_embedding.weight`。
- 为了启用`tie_word_embeddings`，将`llm.model.model.embed_tokens.weight`截断并重新赋值，同时将`lm_head.weight`指向截断后的嵌入权重。

在`pretrained_to_huggingface.py`中，权重的映射更为复杂：
- 从CosyVoice模型中提取`llm`、`speech_embedding`、`llm_decoder`和`llm_embedding`等组件的权重。
- 创建一个新的`lm_head`线性层，其权重和偏置初始化为零，然后将`llm_decoder`的权重和偏置复制到新`lm_head`的相应位置。
- 将`speech_embedding`和`llm_embedding`的权重复制到LLM模型的输入嵌入层的扩展部分。
- 最终，整个LLM模型（包括修改后的`lm_head`和输入嵌入层）被保存为Hugging Face格式。

这些重命名规则精确地处理了CosyVoice特有的模型架构，确保了转换后模型的功能完整性。

**Section sources**
- [huggingface_to_pretrained.py](file://examples/grpo/cosyvoice2/huggingface_to_pretrained.py#L58-L69)
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L98-L106)

## 配置文件适配方法
除了权重转换，配置文件的适配也是确保模型兼容性的关键。`pretrained_to_huggingface.py`脚本负责生成Hugging Face所需的全部配置文件。

分词器（Tokenizer）的适配是其中最重要的部分。脚本首先从CosyVoice模型目录下的`CosyVoice-BlankEN`子目录加载基础的Qwen分词器。然后，它添加了一系列特殊token，包括对话控制token（如`<|im_start|>`、`<|im_end|>`）和语音相关的特殊token（如`[breath]`、`[laughter]`）。最关键的是，它动态生成了6561个语音token `<|s_0|>` 到 `<|s_6560|>`，以及几个结束符token（`<|eos1|>`、`<|eos2|>`、`<|eos3|>`）和任务控制token（`<|sos|>`、`<|task_id|>`）。这些新token被添加到分词器的词汇表中，并相应地调整了LLM模型的嵌入层和解码器大小。

模型配置（Config）的适配同样重要。脚本修改了LLM模型的`generation_config`，设置了`eos_token_id`、`temperature`、`top_p`和`top_k`等生成参数。同时，它更新了模型的`config`对象，明确设置了`eos_token_id`、`vocab_size`，并禁用了`tie_word_embeddings`（因为`lm_head`和输入嵌入层的权重不再共享）。

最后，脚本还为模型定义了一个聊天模板（`chat_template`），该模板指导模型如何处理对话历史，这对于Instruct模式的语音合成至关重要。

**Section sources**
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L64-L133)

## 版本兼容性注意事项
在进行模型格式转换时，必须注意不同版本之间的兼容性问题，以避免转换失败或模型性能下降。

首先，**模型架构版本**必须匹配。`pretrained_to_huggingface.py`脚本是为CosyVoice2模型设计的，它假设模型使用`Qwen2LM`作为LLM组件。如果尝试转换CosyVoice3模型（使用`CosyVoice3LM`），脚本可能会因为找不到预期的组件或权重而失败。同样，`huggingface_to_pretrained.py`脚本中的`speech_token_size`（6561）和`llm_embedding_vocab_size`（2）是针对特定版本的模型硬编码的，如果未来版本改变了这些参数，脚本也需要相应更新。

其次，**依赖库的版本**也至关重要。Hugging Face的Transformers库和CosyVoice项目本身都在持续更新。转换脚本可能依赖于特定版本的库API。例如，`pretrained_to_huggingface.py`中使用了`AutoTokenizer`和`AutoModelForCausalLM`，这些类的接口在不同版本的Transformers库中可能会有变化。建议在转换时使用与模型训练时相同或兼容的库版本。

最后，**硬件和精度兼容性**也不容忽视。`pretrained_to_huggingface.py`脚本在最后将模型转换为`bfloat16`精度，这在现代GPU上能提供良好的性能和内存效率。然而，如果目标部署环境不支持`bfloat16`，可能需要修改脚本以使用`float32`或`float16`。此外，脚本中`pad_to_multiple_of=128`的设置是为了优化GPU内存访问，但这可能不适用于所有场景。

**Section sources**
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L120)
- [llm.py](file://cosyvoice/llm/llm.py#L276-L281)

## 转换流程示例
以下是一个完整的转换流程示例，演示如何使用这两个工具。

### 从Hugging Face转换到CosyVoice预训练格式
```bash
python3 huggingface_to_pretrained.py \
  --hf-cosyvoice2-llm-path /path/to/your/hf_model_checkpoint \
  --output-path /workspace/CosyVoice2-0.5B/llm.pt
```
此命令将位于`/path/to/your/hf_model_checkpoint`的Hugging Face格式模型转换为CosyVoice可加载的`llm.pt`文件。转换完成后，可以将此文件放入CosyVoice模型目录中，与其他组件（`flow.pt`、`hift.pt`）一起使用。

### 从CosyVoice预训练格式转换到Hugging Face
```bash
python3 pretrained_to_huggingface.py \
  --pretrained-cosyvoice2-path /workspace/CosyVoice2-0.5B \
  --save-path ./transformers_cosyvoice2_llm
```
此命令将位于`/workspace/CosyVoice2-0.5B`的CosyVoice预训练模型转换为标准的Hugging Face格式，并保存到`./transformers_cosyvoice2_llm`目录。转换完成后，可以通过`AutoModelForCausalLM.from_pretrained("./transformers_cosyvoice2_llm")`来加载和使用该模型。

**Section sources**
- [huggingface_to_pretrained.py](file://examples/grpo/cosyvoice2/huggingface_to_pretrained.py#L17-L18)
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L17-L22)

## 常见错误与解决方案
在使用转换工具时，可能会遇到一些常见错误。

**键名不匹配**：这是最常见的错误。如果Hugging Face模型的权重键名与`huggingface_to_pretrained.py`脚本中预期的不一致（例如，使用了不同的模块命名），脚本将无法正确提取权重。**解决方案**：仔细检查Hugging Face模型的权重键名，并相应地修改脚本中的字符串匹配逻辑。

**缺失配置文件**：在执行`pretrained_to_huggingface.py`时，如果指定的`--pretrained-cosyvoice2-path`目录下缺少`CosyVoice-BlankEN`子目录，脚本将无法加载基础分词器。**解决方案**：确保CosyVoice模型目录完整，特别是`CosyVoice-BlankEN`这个包含基础Qwen分词器的目录。

**词汇表大小不匹配**：如果在转换过程中，新添加的token数量与模型内部的`speech_token_size`参数不一致，会导致`resize_token_embeddings`操作失败。**解决方案**：检查`cosyvoice2.yaml`配置文件中的`speech_token_size`值，并确保在脚本中生成的语音token数量与之匹配。

**CUDA设备不可用**：`pretrained_to_huggingface.py`脚本需要GPU来执行某些操作（如模型推理）。如果在没有CUDA设备的机器上运行，脚本会自动禁用优化选项，但最终的模型保存可能仍会失败。**解决方案**：在具有GPU的机器上执行转换，或修改脚本以在CPU上运行（可能需要调整精度设置）。

**Section sources**
- [huggingface_to_pretrained.py](file://examples/grpo/cosyvoice2/huggingface_to_pretrained.py#L55-L57)
- [pretrained_to_huggingface.py](file://examples/grpo/cosyvoice2/pretrained_to_huggingface.py#L64-L65)

## 结论
`huggingface_to_pretrained.py`和`pretrained_to_huggingface.py`是连接CosyVoice模型与Hugging Face广阔生态系统的桥梁。通过精确的权重重命名、目录结构映射和配置文件适配，这两个工具实现了模型格式的无缝转换。这不仅极大地便利了模型的共享和发布，也促进了不同研究团队之间的协作。开发者可以轻松地将训练好的模型贡献到Hugging Face Hub，而用户则可以像使用任何其他Transformers模型一样，方便地加载和使用CosyVoice模型。随着语音合成技术的不断发展，这种开放的互操作性将成为推动技术创新和应用落地的关键力量。